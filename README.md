#  RAGent â€“ AI Document Summarizer Powered by RAG

RAGent is a modular, production-ready LLM pipeline that uses **Retrieval-Augmented Generation (RAG)** to intelligently parse, summarize, and answer questions from large, unstructured documents â€” including scanned PDFs.

Whether it's legal, medical, or policy documentation, RAGent leverages OCR, vector search, and LLM reasoning to extract key insights and enable natural language interaction.

---

### ðŸ”§ Features

- ðŸ“„ **OCR-based Extraction** â€“ Extracts text from scanned or image-based documents  
- âœ‚ï¸ **Chunking** â€“ Splits text into structured, overlapping segments for context-aware processing  
- ðŸ” **Vector Search** â€“ Embeds chunks into a vector DB (FAISS/Chroma) for efficient retrieval  
- ðŸ§  **Summarization** â€“ Generates concise section summaries using OpenAI or Cohere  
- ðŸ’¬ **Question Answering** â€“ Answers user queries using context pulled from relevant chunks  
- ðŸ§± **Modular Design** â€“ Separated components for OCR, chunking, LLM utils, QA, and more  
- ðŸ” **.env Support** â€“ Secure credential management with `.env` for API keys and configs

---

### âš™ï¸ Stack

| Type            | Tools & Libraries                                                           |
|------------------|------------------------------------------------------------------------------|
| **Language**     | Python                                                                       |
| **LLMs**         | OpenAI GPT, Cohere, Hugging Face Transformers                               |
| **RAG**          | FAISS / Chroma + OpenAI APIs                                                 |
| **OCR**          | Tesseract OCR                                                                |
| **Vector DB**    | FAISS, pgvector, Qdrant (pluggable)                                          |
| **Chunking**     | Overlapping sliding window w/ metadata                                       |
| **MLOps Ready**  | `.env`, modular utils, ready for API deployment via FastAPI/Streamlit        |

---

### ðŸ“ Project Structure

```text
ðŸ“‚ RAGent/
â”œâ”€â”€ main.py                # Orchestration logic
â”œâ”€â”€ ocr.py                 # OCR text extraction from scanned docs
â”œâ”€â”€ chunker.py             # Document chunking with windowing
â”œâ”€â”€ vector_store.py        # Embedding + storage using FAISS
â”œâ”€â”€ summarizer.py          # LLM-based summarization
â”œâ”€â”€ question_answerer.py   # QA pipeline using RAG
â”œâ”€â”€ llm_utils.py           # Shared helper functions for LLMs
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .env                   # API keys and config variables

**How to run**

# 1. Install dependencies
pip install -r requirements.txt

# 2. Add your keys to .env
echo "OPENAI_API_KEY=sk-..." > .env

# 3. Run the pipeline
python main.py

